{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#@title Install dependencies\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhashlib\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#@title Install dependencies\n",
    "import os\n",
    "from google.colab import files\n",
    "import re\n",
    "import hashlib\n",
    "import random\n",
    "\n",
    "from sys import version_info\n",
    "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
    "\n",
    "USE_AMBER = True\n",
    "USE_TEMPLATES = False\n",
    "PYTHON_VERSION = python_version\n",
    "\n",
    "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
    "  print(\"installing colabfold...\")\n",
    "  os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
    "  if os.environ.get('TPU_NAME', False) != False:\n",
    "    os.system(\"pip uninstall -y jax jaxlib\")\n",
    "    os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
    "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
    "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
    "  os.system(\"touch COLABFOLD_READY\")\n",
    "\n",
    "if USE_AMBER or USE_TEMPLATES:\n",
    "  if not os.path.isfile(\"CONDA_READY\"):\n",
    "    print(\"installing conda...\")\n",
    "    os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\")\n",
    "    os.system(\"bash Miniforge3-Linux-x86_64.sh -bfp /usr/local\")\n",
    "    os.system(\"mamba config --set auto_update_conda false\")\n",
    "    os.system(\"touch CONDA_READY\")\n",
    "\n",
    "if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
    "  print(\"installing hhsuite and amber...\")\n",
    "  os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
    "  os.system(\"touch HH_READY\")\n",
    "  os.system(\"touch AMBER_READY\")\n",
    "else:\n",
    "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
    "    print(\"installing hhsuite...\")\n",
    "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
    "    os.system(\"touch HH_READY\")\n",
    "  if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
    "    print(\"installing amber...\")\n",
    "    os.system(f\"mamba install -y -c conda-forge openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
    "    os.system(\"touch AMBER_READY\")\n",
    "\n",
    "os.system(\"pip install biopython\")\n",
    "\n",
    "# Donwload RNA3Db structure files\n",
    "os.system('wget https://github.com/marcellszi/rna3db/releases/download/incremental-update/rna3db-mmcifs.v2.tar.xz')\n",
    "os.system('tar -xzf rna3db-mmcifs.v2.tar.xz')\n",
    "os.system('rm rna3db-mmcifs.v2.tar.xz')\n",
    "struct_path = \"rna3db-mmcifs.v2/rna3db-mmcifs\"\n",
    "\n",
    "# Donwload RNA3Db sequence files\n",
    "os.system('wget https://github.com/marcellszi/rna3db/releases/download/incremental-update/rna3db-jsons.tar.gz')\n",
    "os.system('tar -xvzf rna3db-jsons.tar.gz')\n",
    "os.system('rm rna3db-jsons.tar.gz')\n",
    "seq_path = \"rna3db-jsons/split.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hash(x,y):\n",
    "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Converter(nn.Module):\n",
    "    def __init__(self, max_seq_len, d_model=64, nhead=8, num_layers=6, dim_feedforward=256, dropout=0.1):\n",
    "        super(Converter, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.input_embedding = nn.Linear(1, d_model)\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len=max_seq_len)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                    dim_feedforward=dim_feedforward, \n",
    "                                                    dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        self.output_linear = nn.Linear(d_model, 20)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        # x shape: (seq_len, batch_size, 1)\n",
    "        \n",
    "        x = self.input_embedding(x)  # Now: (seq_len, batch_size, d_model)\n",
    "        \n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        x = self.output_linear(x)  # Now: (seq_len, batch_size, 20)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        # Convert softmaxxed matrices into one-dimensional indeces\n",
    "        with torch.no_grad():\n",
    "            out = []\n",
    "            for i in range(len(x)):\n",
    "                out.append([])\n",
    "                for j in range(len(x[i])):\n",
    "                    out[-1].append((torch.argmax(x[i][j].detach().cpu())).item()) \n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def create_padding_mask(sequences, pad_value=0):\n",
    "    # sequences shape: (seq_len, batch_size, 1)\n",
    "    return (sequences.squeeze(-1) == pad_value).t()  # (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "def parse_json(path, a, b, max_len=150):\n",
    "    num = -1\n",
    "    seqs = {}\n",
    "    comps = []\n",
    "    macros = []\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    for i in data[\"train_set\"]:\n",
    "        for j in data[\"train_set\"][i]:\n",
    "            for k in data[\"train_set\"][i][j]:\n",
    "                num = num + 1\n",
    "                if data[\"train_set\"][i][j][k][\"length\"]>max_len:\n",
    "                    continue\n",
    "                if num>=a and num<=b:\n",
    "                    seqs[k]=data[\"train_set\"][i][j][k][\"sequence\"]\n",
    "                    comps.append(i)\n",
    "                    macros.append(j)\n",
    "                if num>b:\n",
    "                    break\n",
    "    f.close()\n",
    "    return seqs, comps, macros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = {} # All sequences - may get quite large\n",
    "\n",
    "# Used for file tree searching\n",
    "components = []\n",
    "macro_tags = []\n",
    "\n",
    "\n",
    "# Index to amino acid dictionary\n",
    "# Largely arbitrary, but must stay consistent for any given converter\n",
    "AA_DICT = {\n",
    "    0: \"A\",\n",
    "    1: \"R\",\n",
    "    2: \"N\",\n",
    "    3: \"D\",\n",
    "    4: \"C\",\n",
    "    5: \"Q\",\n",
    "    6: \"E\",\n",
    "    7: \"G\",\n",
    "    8: \"H\",\n",
    "    9: \"I\",\n",
    "    10: \"L\",\n",
    "    11: \"K\",\n",
    "    12: \"M\",\n",
    "    13: \"F\",\n",
    "    14: \"P\",\n",
    "    15: \"S\",\n",
    "    16: \"T\",\n",
    "    17: \"W\",\n",
    "    18: \"Y\",\n",
    "    19: \"V\"\n",
    "}\n",
    "\n",
    "def load_data(path, a=0, b=float('inf'), max_len=150):\n",
    "    # Load up sequences, components, and macro-tags\n",
    "    seqs, components, macro_tags=parse_json(path, a, b, max_len=max_len)\n",
    "    return seqs, components, macro_tags\n",
    "\n",
    "def batch_data(iterable, n=1):\n",
    "    # Data batching function\n",
    "    l = len(iterable)\n",
    "    iter = [(t, s) for t, s in list(iterable.items())]\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iter[ndx:min(ndx + n, l)]\n",
    "\n",
    "def encode_rna(seq):\n",
    "    # Convert RNA sequence to nums to feed into Converter\n",
    "    out = []\n",
    "    for i in seq:\n",
    "        if i==\"A\":\n",
    "            out.append([0])\n",
    "        elif i==\"U\":\n",
    "            out.append([1])\n",
    "        elif i==\"C\":\n",
    "            out.append([2])\n",
    "        elif i==\"G\":\n",
    "            out.append([3])\n",
    "    return out\n",
    "\n",
    "def write_fastas(seqs):\n",
    "    # Write a dict of {tag: seq} to as many FASTA files as needed\n",
    "    os.makedirs('FASTAs', exist_ok=True)\n",
    "    for tag, seq in list(seqs.items()):\n",
    "        if os.path.exists(f'FASTAs/{tag}.fasta'):\n",
    "            continue\n",
    "        f = open(f\"FASTAs/{tag}.fasta\", \"w+\")\n",
    "        f.write(f\">{tag}\\n{seq}\")\n",
    "        f.close()\n",
    "\n",
    "def write_fastas(tags, seqs):\n",
    "    # Write a dict of {tag: seq} to as many FASTA files as needed\n",
    "    os.makedirs('FASTAs', exist_ok=True)\n",
    "    for i in range(len(tags)):\n",
    "        if os.path.exists(f'FASTAs/{tags[i]}.fasta'):\n",
    "            continue\n",
    "        f = open(f\"FASTAs/{tags[i]}.fasta\", \"w+\")\n",
    "        f.write(f\">{tags[i]}\\n{seqs[i]}\")\n",
    "        f.close()\n",
    "\n",
    "def empty_dir(path):\n",
    "    # Empty any directory\n",
    "    for f in os.listdir(path):\n",
    "        os.remove(os.path.join(path, f))\n",
    "    os.rmdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure(tag, path):\n",
    "    # Return the structure of an RNA molecule given its tag and the path to the structure directory\n",
    "    # File directory:\n",
    "    # root\n",
    "    #  -- colabfold.dir\n",
    "    #  -- train_protify.ipynb\n",
    "    #  -- data.dir\n",
    "    #  ---- component 1.dir\n",
    "    #  ------ tag 1.dir\n",
    "    #  -------- tag 1a.cif\n",
    "    #  -------- tag 1b.cif\n",
    "    # ...\n",
    "    index = list(seqs.keys()).index(tag)\n",
    "    component = components[index]\n",
    "    macro_tag = macro_tags[index]\n",
    "    \n",
    "    path = f\"{path}\\{component}\\{macro_tag}\\{tag}.cif\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### Advanced settings\n",
    "model_type = \"auto\" #@param [\"auto\", \"alphafold2_ptm\", \"alphafold2_multimer_v1\", \"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\", \"deepfold_v1\"]\n",
    "#@markdown - if `auto` selected, will use `alphafold2_ptm` for monomer prediction and `alphafold2_multimer_v3` for complex prediction.\n",
    "#@markdown Any of the mode_types can be used (regardless if input is monomer or complex).\n",
    "num_recycles = \"3\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
    "#@markdown - if `auto` selected, will use `num_recycles=20` if `model_type=alphafold2_multimer_v3`, else `num_recycles=3` .\n",
    "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
    "#@markdown - if `auto` selected, will use `tol=0.5` if `model_type=alphafold2_multimer_v3` else `tol=0.0`.\n",
    "relax_max_iterations = 200 #@param [0, 200, 2000] {type:\"raw\"}\n",
    "#@markdown - max amber relax iterations, `0` = unlimited (AlphaFold2 default, can take very long)\n",
    "pairing_strategy = \"greedy\" #@param [\"greedy\", \"complete\"] {type:\"string\"}\n",
    "#@markdown - `greedy` = pair any taxonomically matching subsets, `complete` = all sequences have to match in one line.\n",
    "\n",
    "\n",
    "#@markdown #### Sample settings\n",
    "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
    "#@markdown -  decrease `max_msa` to increase uncertainity\n",
    "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
    "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
    "use_dropout = False #@param {type:\"boolean\"}\n",
    "\n",
    "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
    "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
    "if max_msa == \"auto\": max_msa = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### MSA options (custom MSA upload, single sequence, pairing mode)\n",
    "msa_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
    "pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n",
    "#@markdown - \"unpaired_paired\" = pair sequences from same species + unpaired MSA, \"unpaired\" = seperate MSA for each chain, \"paired\" - only use paired sequences.\n",
    "\n",
    "def a3ms(jobname):\n",
    "    # decide which a3m to use\n",
    "    if \"mmseqs2\" in msa_mode:\n",
    "        a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
    "\n",
    "    elif msa_mode == \"custom\":\n",
    "        a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
    "        if not os.path.isfile(a3m_file):\n",
    "            custom_msa_dict = files.upload()\n",
    "            custom_msa = list(custom_msa_dict.keys())[0]\n",
    "            header = 0\n",
    "            import fileinput\n",
    "            for line in fileinput.FileInput(custom_msa,inplace=1):\n",
    "                if line.startswith(\">\"):\n",
    "                    header = header + 1\n",
    "                if not line.rstrip():\n",
    "                    continue\n",
    "                if line.startswith(\">\") == False and header == 1:\n",
    "                    query_sequence = line.rstrip()\n",
    "                print(line, end='')\n",
    "\n",
    "            os.rename(custom_msa, a3m_file)\n",
    "            queries_path=a3m_file\n",
    "            print(f\"moving {custom_msa} to {a3m_file}\")\n",
    "\n",
    "    else:\n",
    "        a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
    "        with open(a3m_file, \"w\") as text_file:\n",
    "            text_file.write(\">1\\n%s\" % query_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from Bio import BiopythonDeprecationWarning\n",
    "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
    "from pathlib import Path\n",
    "from colabfold.download import download_alphafold_params, default_data_dir\n",
    "from colabfold.utils import setup_logging\n",
    "from colabfold.batch import get_queries, run, set_model_type\n",
    "from colabfold.plot import plot_msa_v2\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "def input_features_callback(input_features):\n",
    "  pass\n",
    "\n",
    "def prediction_callback(protein_obj, length,\n",
    "                        prediction_result, input_features, mode):\n",
    "  model_name, relaxed = mode\n",
    "  pass\n",
    "\n",
    "def train(epochs=50, batch_size=32,tm_score=False, max_seq_len=150):\n",
    "    drive.mount('/content/gdrive')\n",
    "    !mkdir -p \"/content/drive/My Drive/ConverterWeights\"\n",
    "    try:\n",
    "        K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
    "    except:\n",
    "        K80_chk = \"0\"\n",
    "        pass\n",
    "    if \"1\" in K80_chk:\n",
    "        print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
    "        if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
    "            del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
    "        if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
    "            del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
    "\n",
    "    # For some reason we need that to get pdbfixer to import\n",
    "    if f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
    "        sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
    "\n",
    "    conv = Converter(max_seq_len=max_seq_len)\n",
    "    conv.train()\n",
    "    optimizer = torch.optim.Adam(conv.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "    model_type = set_model_type(False, \"auto\")\n",
    "    download_alphafold_params(model_type, Path(\".\"))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in batch_data(seqs, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            # batch: ([(tag, seq), (tag, seq),...])\n",
    "\n",
    "            # LAYER 1: RNA-AMINO CONVERSION\n",
    "            tags = [s[0] for s in batch]\n",
    "            structs = [get_structure(tags[i]) for i in range(len(tags))]\n",
    "\n",
    "            # Check that structure files exist\n",
    "            # if not os.path.isfile(get_structure(tags[0])):\n",
    "            #     continue\n",
    "            \n",
    "            # Preprocessing sequences\n",
    "            processed_seqs = [torch.Tensor(np.transpose(np.array(encode_rna(s[1])), (0,1))) for s in batch] # (batch, seq, base)\n",
    "\n",
    "            # Send sequences through the converter\n",
    "            aa_seqs = [conv(s) for s in processed_seqs][0] # (seq, batch, aa)\n",
    "            temp = []\n",
    "            \n",
    "            # Reconvert to letter representation\n",
    "            for i in range(len(aa_seqs)):\n",
    "                temp.append(''.join([AA_DICT[n] for n in aa_seqs[i]]))\n",
    "                    \n",
    "            aa_seqs = temp # (seq: String, batch)\n",
    "\n",
    "            final_seqs = {} # {tag: seq}\n",
    "            for i in range(len(tags)):\n",
    "                final_seqs[tags[i]] = aa_seqs[i]\n",
    "            write_fastas(final_seqs)\n",
    "\n",
    "            num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
    "            #@markdown - specify how many of the top ranked structures to relax using amber\n",
    "            template_mode = \"none\" #@param [\"none\", \"pdb100\",\"custom\"]\n",
    "            #@markdown - `none` = no template information is used. `pdb100` = detect templates in pdb100 (see [notes](#pdb100)). `custom` - upload and search own templates (PDB or mmCIF format, see [notes](#custom_templates))\n",
    "\n",
    "            use_amber = num_relax > 0\n",
    "            use_cluster_profile = True\n",
    "\n",
    "            if template_mode == \"pdb100\":\n",
    "                use_templates = True\n",
    "                custom_template_path = None\n",
    "            elif template_mode == \"custom\":\n",
    "                custom_template_path = os.path.join(jobname,f\"template\")\n",
    "                os.makedirs(custom_template_path, exist_ok=True)\n",
    "                uploaded = files.upload()\n",
    "                use_templates = True\n",
    "            for fn in uploaded.keys():\n",
    "                os.rename(fn,os.path.join(custom_template_path,fn))\n",
    "            else:\n",
    "                custom_template_path = None\n",
    "                use_templates = False\n",
    "\n",
    "            for i in range(len(final_seqs)):\n",
    "                queries, _ = get_queries(f'FASTAs/{list(final_seqs.keys())[i]}')\n",
    "                jobname = hash(list(final_seqs.keys())[i])\n",
    "                results =  run(\n",
    "                    queries=queries,\n",
    "                    result_dir=jobname,\n",
    "                    use_templates=USE_TEMPLATES,\n",
    "                    custom_template_path=None,\n",
    "                    num_relax=num_relax,\n",
    "                    msa_mode=msa_mode,\n",
    "                    model_type=model_type,\n",
    "                    num_models=1,\n",
    "                    num_recycles=num_recycles,\n",
    "                    relax_max_iterations=relax_max_iterations,\n",
    "                    recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
    "                    num_seeds=num_seeds,\n",
    "                    use_dropout=use_dropout,\n",
    "                    model_order=[1,2,3,4,5],\n",
    "                    is_complex=False,\n",
    "                    data_dir=Path(\".\"),\n",
    "                    keep_existing_results=False,\n",
    "                    rank_by=\"auto\",\n",
    "                    pair_mode=pair_mode,\n",
    "                    pairing_strategy=pairing_strategy,\n",
    "                    stop_at_score=float(100),\n",
    "                    prediction_callback=prediction_callback,\n",
    "                    dpi=200,\n",
    "                    zip_results=False,\n",
    "                    save_all=False,\n",
    "                    max_msa=max_msa,\n",
    "                    use_cluster_profile=use_cluster_profile,\n",
    "                    input_features_callback=input_features_callback,\n",
    "                    save_recycles=False,\n",
    "                    user_agent=\"colabfold/google-colab-main\",\n",
    "                )\n",
    "            \n",
    "            from protein_to_rna import protein_to_rna\n",
    "            path = \"\"\n",
    "            for file in os.listdir(f\"/{jobname}\"):\n",
    "                if file.endswith(\".pdb\"):\n",
    "                    path = os.path.join(f\"/{jobname}\", file)\n",
    "                    break\n",
    "            loss = protein_to_rna(path, get_structure(list(final_seqs.keys())[i], struct_path), tm=tm_score)\n",
    "            empty_dir(f\"/{jobname}\")\n",
    "            loss = torch.Tensor([loss])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        torch.save(conv, f'/content/gdrive/My Drive/ConverterWeights/converter_epoch_{epoch}.pt')\n",
    "        torch.save(conv.state_dict, f'/content/gdrive/My Drive/ConverterWeights/converter_params_epoch_{epoch}.pt')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(seq_path, 0, 1615)\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
